\section{FEM Code Implementation}
contains development of the program code with focus on the assembly of the system and its solving, the process of parallelization %TODO
 
 
 
 \subsection{Introduction to libMesh}
 The libMesh finite element library was stared as part of the Ph.D. work of Benjamin Kirk \cite{kirk2007adaptive}. It is a tool for numerical simulation of partial differential equations on serial and parallel platforms and uses the finite element method. Major goals are to provide data structures and algorithms for applications that need implicit numerical methods, parallel computing, adaptive mesh refinement techniques, or, a combination of them. Further, it simplifies many programming details for the user, such as: Reading the mesh from file, initialize data structures, solving the dicretized system, and, writing out the results \cite{kirk2013case}.
 
 LibMesh allows discretization of one, two and three dimensional problems using several geometric element types, including: Edges, quadrilaterals, triangles, tetrahedra, hexahedra, pyramids, prisms and some infinite elements of quadrilaterals or hexahedra. Finite elements include traditional first and second order Lagrange, as well as arbitrary order hierarchical bases, and N\'{e}d\'{e}lec elements of first type.
 
 Mesh partitioning is available in libMesh through interfaces to several external packages, but also some internal partitioning algorithms are provided: Linear and centroid partitioner as examples of internal algorithms, Metis and ParMetis \cite{karypis1998fast} as examples for external partitioner. In addition to these two, libMesh includes interfaces to solver libraries such as PETSc \cite{petsc2015url} and LASPack \cite{laspack2015url}. Thus, libMesh provides several linear equation solvers such as GMRES, CG, Bi-CGSTAB, QMR, and preconditioners like Jacobi, incomplete LU factorization and incomplete Cholesky factorization. The choice of an appropriate solver and preconditioner is made by the user at runtime.
 
 A wide variety of mesh formats are supported by libMesh to facilitate use of complex geometries. The following is an incomplete list of supported input and output formats: Nemesis, TetGen, I-deas Universal UNV, AVS's ASCII UCD, Visualization Toolkit VTK, libMesh formats XDR/XDA, ExodusII, GMSH, LANL's General Mesh Viewer GMV, GnuPlot (only output), Matlab (only input) \cite{kirk2013case}.
 
 An example program using the libMesh library would look like listing \ref{lst1}.
 \begin{lstlisting}[caption=Example libMesh program,label=lst1]
#include "libmesh/libmesh.h"
#include "libmesh/additional_libmesh_components"

using namespace libMesh;

void assemble_something(EquationSystems& es, const std::string& system_name);

int main (int argc, char** argv)
{
	LibMeshInit (int argc, char** argv);
	
	Mesh mesh( init.comm() );
	
	// mesh generation via MeshTools::Generation::build_... or mesh import from file via mesh.read(std::string filename)
	
	EquationSystems es(mesh);
	
	LinearImplicitSystem& system = es.add_system<LinearImplicitSystem> ("example system");
	
	system.add_variable ("a", FIRST);
	system.add_variable ("b", SECOND, LAGRANGE);
	
	system.attach_assemble_function (assemble_something);

	es.init();
	
	system.solve();
	
	VTKIO (mesh).write_equation_systems ("out.pvtu", es);
	
	return 0;
}
 \end{lstlisting}
 In fact, this is the base construction of nearly every libMesh program. It starts with including libMesh components that are needed by the program, e.g. \textit{mesh.h, equation\_systems.h, fe.h}. Then, the library needs to be initialized (line 10). This is necessary because it may depend on a number of other external libraries like MPI and PETSc that require initialization before use. On the other hand, if the \texttt{\textbf{LibMeshInit}} object goes out of scope, the other libraries are finalized automatically by libMesh. Next, a mesh is created (lines 12-14) on the default MPI communicator (even if the program is executed single-threaded). The mesh can either be read from file or created by internal mesh generation tools. In line 16 an equation systems object is created. It can contain multiple different systems. Here, only one linear implicit system is added to the object (line 16). Each system can contain multiple variables of different approximation orders (see lines 20/21). Many systems require a user-defined function that will assemble the (linear) system (lines 6 and 23). Now, the data structures for equation system must be initialized which is done in line 25. The solving of the systems is done in line 27 of the code. This one line of code calls the assemble function defined earlier and invokes the default numerical solver. If the external library PETSc is installed, the solver can be controlled from the command line by the user. After solving the system, the solution can be written to file; here, for example, the results are written to a VTK-formatted plot file (line 29).
 
 \subsection{Implementation Details}
 details about the implementation with the libmesh FEM framework \\%TODO
 - short overview: stand-alone-version: gets input parameters from user and mesh file and produces results stored in output file

 
  \subsubsection{Initialization}
   \begin{itemize}
   	\item loading of parameters: which parameters are needed by the user\\
   	- possion's ratio $\nu$ required, no default value\\
   	- elastic modulus $E$ required, no default value\\
   	- mesh thickness $t$ required, no default value\\
   	- debugging messages, default false\\
   	- mesh file required, no default file, type msh oder xda, xdr, see next section for more details\\
   	- output file, if not given, no output is made
   	
   	\item special parameters for petsc:\\
   	- solver-type\\
   	- preconditioner-type
   \end{itemize}
   
   
   
  \subsubsection{Mesh file import}
   \begin{itemize}
   	\item wie sieht mesh file aus, was muss definiert sein:\\
   	- vertices mit coordinates\\
   	- elements\\
   	- boundary conditions
   	
   	\item beispiel im libmesh-format xda
   	
   	\item welche typen werden akzeptiert: xda, gmsh implementiert; weitere als erweiterung denkbar
   	
   	\item welche ids für bcs müssen verwendet werden: auflistung der bc-id und ihre bedeutung\\
   	- 0: clamped/simple supported\\
   	- 1: simply supported/clamped\\
   	- 2: inner node, part of preCICE interface region (only used by preCICE coupled variant)\\
   	- 20: same as 0 but additionally part of preCICE interface region (only used...)\\
   	- 21: same as 1 but additionally part of preCICE ...
   	
   	\item especially for standalone-case: force file\\
   	- structure with short example matching the mesh-example\\
   	- entries defined in global coordinate system like vertices, too
   \end{itemize}
   
   
   
  \subsubsection{System setup}
   \begin{itemize}
  	\item setting up libmesh\\
   	- LinearImplicitSystem, erklärung aus doxygen\\
   	- 6 variablen erstellen\\
    - set boundary condition types, DirichletBoundary class\\
	  nochmal auf theorieteil eingehen
   \end{itemize}
   
   
   
  \subsubsection{Matrix and vector assembly}
   \begin{itemize}
    \item material matrices: D\_m und D\_p
    
   	\item creation of local and global stiffness matrix
   	
   	\item integral with gauss-quadrature
   	
   	\item read corresponding entry from force array and set it in the right-hand-side vector

   	\item storing already processed nodes with unordered\_set-structure
   \end{itemize}
   
   
   
  \subsubsection{Solving the system}
   \begin{itemize}
   	\item solving part is just one line. calls the assemble-function and the defined solver (e.g. if PETSc is installed)
   	
   	%\item hier kann man aber schreiben, mit was libmesh umgehen kann an lösern,
    
    \item which settings are possible (error-eps, \#iters)
    
    \item build\_solution\_vector
   \end{itemize}
   
   
   
  \subsubsection{Output}
   - for standalone-version output as exodus2-file\\
   - exodus2 can be read by ParaView, parallel vtk-output is not supported by libMesh
   
   - according to the user command line parameter, output file is written to specified file or not at all
 
 
 
 \subsection{Parallelization with MPI}
 additional steps to make the code ready for multi process execution with MPI\\
  \subsubsection{libMesh requirements}
   grundsätzlich ist zum lösen des gleichungssystem mit mehreren prozessen petsc als externe lib notwendig
  
  \subsubsection{Partitioning the mesh}
   am mesh muss nichts verändert werden, da libmesh automatisch eine partitionierung des meshes vornimmt (kann aber verbessert werden)
   
  \subsubsection{Local elements}
   grundsätzlich sorgt libMesh dafür, dass jeder prozessor nur zugriff auf "seine" element, knoten usw. hat. Das wird hier wichtig mit änderungen an den iteratoren usw.
  
  \subsubsection{Assembly changes}
   damit rhs korrekt gesetzt wird muss über die prozessgrenzen hinweg klar sein, ob knoten bereits bearbeitet wurde oder nicht. wie das gelöst wurde kommt hier rein\newline