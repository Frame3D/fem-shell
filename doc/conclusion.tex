\section{Summary and Conclusions}
 This chapter summarizes the important results achieved by the thesis and presents a discussion of these results. In the remainder of this chapter an outlook to future development is given.
 
 
 \subsection{Summary}
  % what was the goal
  The aim of the thesis was to develop a FEM-code being able to be coupled in a fluid-structure interaction. The program development should be supported by a FEM framework. Comparison aspects had to be created and an evaluation of several FEM libraries was performed. The implemented FEM-code was to be validated with example problems. The coupling part should be managed by the preCICE tool. The overall focus was on creating a well documented and easily readable and maintainable code, ready for further development and extensions.
  % evaluation
  For the FEM framework evaluation different comparison aspects were introduced. Besides organizational requirements like an open-source code, C++ as development programming language and a wide and accurate documentation of the functions and classes, numerical and programmatic aspects were considered. The last aspects included the possibility to parallelize the code via MPI, a large collection of finite element types and built-in iterative linear solvers. During the evaluation process two libraries were practically tested, the first one being MFEM. Because of difficulties in use, another library - libMesh - was tested and finally chosen for the program development.  
  % theory
  In this thesis flat shell elements were implemented. Such an element is composed of a plane and a plate element part that are superimposed in order to construct the final shell element. Two different types of finite elements were considered: A three-node triangular element, denoted as Tri-3 and a four-node quadrilateral element, denoted as Quad-4. Six models had to be implemented in the scope of this thesis: A plane, plate and shell element for each of the two discretizations. Therefore, existing models like the Discrete Kirchhoff Quadrilateral were selected for implementation.
  % implementation
  The libMesh framework assisted with developing the FEM-code by providing many components and classes that only needed to be configured and put into the program like blocks. The import of mesh files and the construction of the internal representation of the mesh as nodes, edges and elements is done by libMesh. Also, the creation of a solver and the boundary conditions is simplified by using predefined classes. The solving of the system is done by libMesh or by the external library PETSc which is required as soon as the program is executed in parallel. The major task for the developer was to create the assembly function that construct the overall system matrix and right-hand side. Here, every element was transformed from global space to a local coordinate system in order to assemble its local stiffness matrix. The local stiffness matrices were then re-transformed into global space in order to be added to the global system matrix. The adding step as well as the constraining of elements at the boundary is on the other hand performed by libMesh. Due to the fact that MPI is integrated in libMesh throughout the library, the parallelization of the program only required minor modifications to the code.
  % coupling
  The coupling tool preCICE was used to create a second version of the program that is capable of being coupled with other solvers in a multi-physics simulation. preCICE serves as connector between the single solvers, managing data mapping and communication, for instance. One goal of preCICE is to require only minimal changes to the solver's code in order to integrate its API and make it coupling-ready. This was confirmed, as only a few lines of code had to be changed besides additional data structures necessary for inter-solver communication.
  % validation
  Every implemented element model were validated with respect to accuracy. In addition to that the convergence was tested, i.e. the behavior of accuracy with an increasing level of mesh subdivision. The parallelization was validated with the same example problem solved by an increasing number of processes and measuring the execution time of different code parts like the matrix assembly or the solving step. The coupling was tested with an fluid-structure interaction problem with the developed program and an OpenFOAM fluid solver as participants. In the test a flow was driven through a pipe with an elastic structure fixed at the bottom side of the tube as deformable obstacle for the flow.
 
 \subsection{Conclusion}
 % dieser teil sollte lang sein
 % es wurden verschiedene frameworks mit einander verglichen und das geignetste ausgewählt. MFEM und libMesh waren in der näheren auswahl. libMesh ist nachträglich betrachtet tatsächlich eine gute wahl gewesen. vorher wurde probiert mit MFEM zu arbeiten, aber gewisse probleme haben einen wechsel provoziert.
  The evaluation of FEM frameworks yield two suitable libraries for the program's development. The first framework that was used was MFEM. A problem in the practical use made it necessary to switch to another library. Two dimensional geometrical elements are processed within the scope of the program. These elements can be positioned arbitrarily in the three dimensional space. When defining 2D elements in a mesh file that is specified to be in 3D space lead to undefined behavior or even the crashing of the program. If 2D elements were specified with 3D coordinate in a mesh file that were specified to be in 2D space the third coordinate component was ignored. Every tested solution to this problem brought new problems and therefore the second suitable library was taken into account. The libMesh framework offered basically the same features as MFEM although it has other specializations like the focus on adaptive mesh refinements. With the help of this framework the program could be developed without any major issues. The possibilities of libMesh qualify for further use in future development of the structure solver.
  
 % es wurden 6 finite elemente implementiert und getestet. das war nötig um einen geiegneten strukturlöser für die kopplung zu haben.
  In order to offer an appropriate structure solver for coupling purposes, all element components used for the implementation of flat shell elements were validated separately. Hence, several example problems were selected that provided either an analytical solution or solutions created by commercial and approved software. The tests of the Tri-3 and Quad-4 plane elements showed very good accuracy compared to the commercial software SAP2000 with a difference of less than $0.03\%$. The first example problem also illustrated that the arrangement of elements in the mesh has an important part in accuracy. The test of the Tri-3 plate element indicated a first impression of the involvement of mesh subdivisions: While the accuracy was only around $9\%$ for a $4\!\times\!4$ mesh refinement, the accuracy increased to only around $1\%$ difference to the exact value. Another involved factor got visible in the Quad-4 plate element test: The type of loading has different influence to the accuracy of the example problem. A uniform load where the forces are distributed throughout the whole plate leads to good accuracy even with coarse mesh refinement. For a concentrated loading applied on only one node at the center of the plate, the mesh refinement must be increased to gain the same level of accuracy. This behavior can only be observed with plate elements and is due to the chosen finite element models. A eight-node quadrilateral element would approximate edge twists better and therefore lead to more accurate results. The combinations of plane and plate elements produce a shell elements. These were tested with an example problem where an I-beam was fixed at the one end and nodal forces were applied at the other end facing inwards to the middle of the beam. This results in deformations in all three spatial axes. The accuracy of the Tri-3 element was better compared to the Quad-4 element although the difference between the $x$-, $y$- and $z$-displacement is larger when compared to the quadrilateral element.
 % die einzelnen tests (nochmal) analysieren (accuracy, etc.)
 % test der convergence
 % test der parallelität
 % test der kopplung
  In a separate series of tests the element's convergence with respect to accuracy was validated. The level of mesh subdivisions was increased from test to test. While all tests showed that the higher the mesh refinement is the better the analytical solution is approximated by the solver, the test with uniform loading and clamped boundary conditions sticks out: The accuracy stagnates around $1.7\%$ difference to the exact value independently from the number of elements forming the plate. This behavior cannot be explained and might only be specific to this scenario. The other tests confirmed previous observations: With a uniform loading the accuracy is high even for coarse meshes while concentrated loadings need finer meshes. With clamped boundary conditions the solutions show large difference to the analytical result if the mesh is not very fine subdivided.
  
  The parallelization of the program was validated in an additional test. For this, three different times were measured while executing the program: The time needed to assembly the system matrix and right-hand side, the time to solve the system and the overall time from the beginning of the program to the last line of code. This validation must be split in halves since it contains code that is outside of the scope of this thesis: The solving is done by PETSc in parallel. The benefits with respect to time saving can only be observed not explained. The other half is the assembly of the system. Here, every element of the mesh must be processed. This task can be efficiently partitioned and lend to the single processes. Therefore the time for assembling the matrix is nearly halved from the sequential to the execution with two processes. This would lead to a speedup of around $100\%$ for this part of the code and without further tests with more processes. Since every element can predominantly be processed independently from the others this speedup value is possible, though. The bottleneck in this case is the adding of the local matrices to the overall system matrix that is done by libMesh. The solver behaves less efficient compared to the assembly function. Here, the benefit of multiple processes is also visible, but not as dominant as before. The tests were performed on an Intel dual-core processor that uses hyper-threading. This technology lead to even shorter times when both, physical and logical cores are active. Though, the two additional logical cores cannot replace a real quad-core processor. This is especially noticeable when using three processes, i.e. the two physical cores and one logical core: The computation times even rise compared to only two processes but stay still below the single-threaded run. All in all one can state that the solver is capable of being executed in parallel and offers good performance with multiple processes. The solver takes the biggest part of the runtime at least for big meshes. For very small meshes the time to import the mesh, initialize the system and write the outputs - which would otherwise cost minimal time - dominates the execution time.
  
  The last validation test was a fluid-structure interaction where the developed program was coupled with a fluid solver written with the OpenFOAM framework and connected via the preCICE tool.
  %TODO HIER FEHLT DANN NOCH DIE ANALYSE DES TESTS
 
 % resumé: löser geeignet für multi-physics, wenn unterteilung des meshs entsprechend hoch ist, damit accuracy stimmt. dank gut skalierender parallelisierung möglich
  As a resum\'{e} the developed structure solver can be seen as qualified for multi-physics simulation under the assumption of a fine level of mesh subdivision for good accuracy. The good performance in parallel scaling makes it possible to provide such a fine subdivision level without risking to spend too much time for processing of the increased number of elements.

 \subsection{Future Development}
  The developed FEM-code successfully implemented flat shell elements and is able to work in coupled multi-physics simulations. The validation showed good accuracy for fine mesh subdivisions. The program was designed to be able to easily introduce new models for plane and plate elements, for example quadratic or cubic quadrilateral elements with 8 or 9 nodes. This would enhance the accuracy further. The requirements of the developed program included two dimensional elements. One could expand this limit also to beam and truss elements of one dimension or even to three dimensional solid elements. The libMesh library and the coupling tool preCICE would support such features.
  
  All scenarios considered in this work so far had constant conditions. The finite element idealization could be extended to situations that are time dependent and simultaneously add dynamic behavior to the elastic structures. When displacements of an elastic body vary with time two additional forces must be introduced, namely the inertia or acceleration and resistance opposing the motion. Therefore, a new type of solver must be introduced as well which might also be provided by the libMesh framework.
\newpage